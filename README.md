# Дослідження вендора великих мовних моделей: Cohere

> **Виконав:**  
> студент групи ІПЗ-51м  
> Ейсмонт Віктор

## Зміст

## Словник термінів


## 1. Вступ
Компанія Cohere — один із ключових гравців у сфері штучного інтелекту, що спеціалізується на створенні великомасштабних мовних моделей (Large Language Models, LLM) для бізнес-кейсів. На відміну від багатьох компаній, які орієнтуються на широкого споживача, Cohere фокусується на enterprise-рішеннях, забезпечуючи інструменти для обробки природної мови (Natural Language Processing, NLP) на корпоративному рівні, включно з генерацією тексту, семантичним пошуком і класифікацією документів.
З моменту свого заснування компанія позиціонує себе як розробник моделей, які можна легко інтегрувати у вже існуючу інфраструктуру — локально, у приватні хмари або в екосистему публічних провайдерів. Ключова увага приділяється конфіденційності даних, масштабованості та можливості кастомізації моделей під специфіку домену. Моделі Cohere побудовані на архітектурі Transformer, що дозволяє ефективно працювати з довгими контекстами, оптимально масштабуватися та досягати високої якості завдяки великій кількості параметрів (model parameters).

У своїй діяльності компанія розвиває три основні напрямки:
* Генеративні моделі (серія Command)
* Моделі вбудовувань (Embeddings) для семантичного аналізу
* Моделі ранжування (Rerank) для покращення релевантності пошуку
  
Таким чином, Cohere виступає не лише як постачальник LLM, а як платформа для побудови повноцінних мовних екосистем, адаптованих для різних галузей — від фінансів і юридичних сервісів до електронної комерції та хмарних рішень.

## 2. Еволюція великих мовних моделей Cohere
## 2.1. Старт компанії та перше покоління моделей (2019–2020)
Компанія Cohere була заснована у 2019 році групою дослідників з Google Brain, які брали безпосередню участь у розвитку архітектури Transformer. Вихідці з фундаментальних досліджень у галузі глибокого навчання, засновники Cohere зосередилися на створенні масштабованих мовних моделей, орієнтованих на практичне застосування в бізнес-середовищах.
Перший етап розвитку компанії був присвячений формуванню базових генеративних мовних моделей та моделей вбудовувань (Embeddings) для ключових задач обробки природної мови (NLP).
Характерні риси цього етапу:
* використання архітектури Transformer Decoder як основи генерації тексту;
* навчання моделей на великих загальних текстових корпусах;
* фокус на задачах текстової генерації, автодоповнення та базового семантичного пошуку;
* поява перших Cohere Base Models, які ще не були поділені на брендові лінійки Command чи Embed;
* оптимізація продуктивності, латентності та енергоефективності з урахуванням enterprise-використання.
  
Цей період заклав технічний фундамент, на якому згодом сформувалася повноцінна екосистема моделей Cohere.

## 2.2. Перехід до спеціалізованих моделей Embeddings (2021)
У 2021 році Cohere зробила стратегічний акцент на семантичних ембеддингах, усвідомивши, що корпоративні сценарії потребують не лише генерації тексту, а й високоякісного розуміння змісту. Саме цей крок став одним із ключових факторів диференціації Cohere на ринку LLM.
Ключові інновації цього етапу:
* розробка перших Sentence Embeddings моделей, оптимізованих для пошуку та класифікації;
* підтримка багатомовності (Multilingual Embeddings);
* адаптація моделей під корпоративні сценарії: пошук по документах, кластеризація, категоризація знань;
* активна інтеграція з векторними базами даних та пошуковими рушіями (Pinecone, Elasticsearch, Weaviate).

Моделі цього покоління стали основою для подальшої еволюції серії Embed v2 → v3 → v4, яка сьогодні використовується у більшості enterprise-RAG систем.

## 2.3. Поява модельної лінійки Command — генеративні LLM нового рівня (2022–2023)
У 2022–2023 роках Cohere вийшла на новий рівень, представивши лінійку генеративних моделей Command, орієнтованих на складні бізнес-сценарії та інструкційне використання.

Особливості моделей Command:
* оптимізація під instruction-following та діалогові сценарії;
* глибше розуміння намірів користувача (User Intent Understanding);
* суттєво збільшене контекстне вікно (context window);
* покращена робота з великими корпоративними документами;
* підтримка fine-tuning на приватних і доменно-специфічних даних.
  
Моделі Command свідомо позиціонувалися як enterprise-альтернатива споживчим LLM (ChatGPT, PaLM2), з акцентом на безпеку, контроль даних та можливість приватного розгортання.

## 2.4.  Aya — багатомовні та відкриті моделі як окремий напрям розвитку (2023–2024)
Окремим і стратегічно важливим напрямом стала поява Aya — серії багатомовних відкритих мовних моделей, розроблених Cohere у співпраці з глобальною дослідницькою спільнотою.

Ключові особливості Aya:
* підтримка десятків мов, включно з мовами з низьким ресурсним покриттям;
* орієнтація на multilingual NLP та cross-lingual transfer learning;
* відкритий підхід до досліджень і розвитку (open models);
* зменшення мовної та культурної упередженості в LLM;
* можливість використання в академічних і некомерційних дослідженнях.
  
Aya підкреслює прагнення Cohere не лише до комерційного успіху, а й до глобальної інклюзивності та демократизації ШІ.

## 2.5. Розвиток моделей Rerank — покращення пошукових систем (2023–2024)
Наступним етапом стала поява спеціалізованих моделей Rerank, призначених для підвищення якості інформаційного пошуку.

Основні характеристики Rerank:
* використання cross-encoder архітектури для високоточного порівняння «запит–документ»;
* застосування у пошукових системах, рекомендаційних механізмах та RAG-архітектурах;\
* підтримка обробки довгих текстів;
* оптимізація під сценарії Retrieval-Augmented Generation (RAG).
* 
Моделі Rerank 3–3.5 стали еталонними для задач семантичного ранжування у корпоративних системах знань.

## 2.6. Мультимодальність, великі контексти та Embed v4 — сучасний етап (2024–2025)
У 2024–2025 роках Cohere зосередилась на масштабуванні моделей і розширенні їх функціональності.
Ключові інновації етапу:
Embed v4 — мультимодальні ембеддинги (текст + зображення), оптимізовані для RAG;
* покращена семантична узгодженість між різними типами даних;
* глибока інтеграція з хмарними платформами (AWS Bedrock, Oracle Cloud, GCP);
* підтримка приватних розгортань: VPC, on-premise;
* використання високоякісних curated datasets;
* підтримка дуже довгих контекстів у моделях Command.
* На цьому етапі Cohere закріпила статус провідного enterprise-постачальника LLM та embedding-технологій.

## 2.7. Поточна філософія розвитку (2025+)
Подальший розвиток Cohere зосереджений на:
* доменно-орієнтованих моделях (legal, finance, healthcare);
* підвищенні якості reasoning та аналітичних можливостей;
* розширенні мультимодальності;
* оптимізації обчислювальних витрат;
* безпечних та ізольованих enterprise-розгортаннях.

## 3. Карта моделей
### Порівняльна таблиця сімейства великих мовних моделей Cohere
|  **Модель** | **Розмір моделі** | **Тип** | **Дата випуску** |  **Довжина контексту** | **Токенізатор** | **Ліцензія** | **Model card / Docs** |
| :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |	
| Cohere Base (early) | Не розкрито | Текст | 2020 | ~2K	| BPE	| Proprietary |	[Model Card](https://docs.cohere.com/docs/models) |
| Embed v1 | Не розкрито | Ембеддинги (текст) | 2021 | N/A |	BPE	 | Proprietary | [Model Card] (https://docs.cohere.com/docs/embeddings) |
| Embed v2 | Не розкрито | Ембеддинги (текст) | 2022 | N/A | BPE | Proprietary | [Model Card] (https://docs.cohere.com/docs/embeddings) |
| Embed v3 | Не розкрито | Багатомовні ембеддинги | 2023 | N/A | BPE | Proprietary | [Model Card] (https://docs.cohere.com/docs/embeddings) |
| Embed v4 | Не розкрито | Текст + зображення (multimodal embeddings) | 2024 | N/A | BPE	| Proprietary | [Model Card] (https://docs.cohere.com/docs/embeddings) |
| Command | Не розкрито | Генеративний текст | 2022 | ~4K | BPE | Proprietary | [Model Card] (https://docs.cohere.com/docs/command) |
| Command R | ~7B (офіційно підтверджено) | Генеративний текст (RAG-оптимізований) | 2024 | 128K | BPE | Proprietary | [Model Card] (https://docs.cohere.com/docs/command-r) |
| Command R+ | Не розкрито | Генеративний текст (enhanced RAG) | 2024 | 128K | BPE | Proprietary | [Model Card] (https://docs.cohere.com/docs/command-r-plus) |
| Command A | ~111B | Генеративний текст + reasoning | 2024 | 256K | BPE | Proprietary | [Model Card] (https://docs.cohere.com/docs/command-a) |
| Rerank v2 | Не розкрито | Reranking (cross-encoder) | 2022 | ~4K | BPE | Proprietary | [Model Card] (https://docs.cohere.com/docs/rerank) |
| Rerank v3 | Не розкрито | Reranking (RAG) | 2023 | ~8K | BPE | Proprietary | [Model Card] (https://docs.cohere.com/changelog) | 
| Rerank 3.5 | Не розкрито | Reranking (enterprise search) | 2024 | ~16K | BPE | Proprietary | [Model Card] (https://docs.cohere.com/changelog) | 
| Aya 23 | ~8B, ~35B | Багатомовний текст | 2023 | ~4K | SentencePiece | Open (Research) | [Model Card] (https://cohere.com/research/aya/aya-23-technical-report.pdf?utm_source=chatgpt.com) |
| Aya 101 | ~13B | Багатомовний текст | 2024 | ~8K | SentencePiece | Open (Research) | [Model Card]  (https://huggingface.co/CohereLabs/aya-101) |

## 4. Ключові персони Cohere
Розвиток екосистеми Cohere базується на поєднанні глибоких академічних досліджень у сфері штучного інтелекту та практичної орієнтації на корпоративні сценарії використання. Компанія з самого початку позиціонувала себе як постачальник інфраструктурних мовних моделей, призначених для інтеграції у бізнес-процеси, а не як продукт масового споживання.
Важливою особливістю Cohere є розділення діяльності на:
* комерційний напрям (моделі Command, Embed, Rerank);
* дослідницький напрям Cohere For AI, який займається відкритими моделями та фундаментальними дослідженнями (лінійка Aya).
---
| **Ім'я** | **Позиція** | **Роль** | **Вплив** | 
| :----: | :----: | :----: | :----: | 
| **Айдан Гомес (Aidan Gomez)** | CEO, співзасновник | Технічний та стратегічний лідер | Один з авторів архітектури Transformer. Визначив довгострокову стратегію Cohere як платформи для enterprise-AI з акцентом на контроль даних, приватність та інтеграцію у корпоративні системи |
| **Нік Фрост (Nick Frosst)** | Співзасновник | Дослідження та стратегія | ПВідповідає за поєднання фундаментальних досліджень із прикладними бізнес-моделями. Підтримує розвиток відкритих дослідницьких ініціатив без шкоди для комерційних продуктів |
| **Іван Чжан (Ivan Zhang)** | Співзасновник | Інженерна архітектура | Один з ключових архітекторів внутрішньої інфраструктури навчання та масштабування моделей. Його робота забезпечила фокус на ефективність, latency та стабільність моделей |
| **Сара Хукер (Sara Hooker)** | Head of Cohere For AI | Керівниця дослідницького напряму | Очолює відкриті дослідження, включно з ініціативою Aya. Її робота спрямована на багатомовність, підтримку low-resource мов та етичні аспекти ШІ |
| **Філіпп Шмід (Philipp Schmid)** | Senior AI Engineer / Developer Advocate | Практичне впровадження моделей | Відіграє важливу роль у популяризації підходів Cohere до побудови RAG-систем, семантичного пошуку та embeddings у реальних корпоративних середовищах |
| **Закриті дослідницькі команди Command / Embed / Rerank** | Core Research & Engineering | Розробка моделей | Cohere дотримується підходу, за якого основна увага приділяється продукту, а не публічній персоналізації окремих інженерів |
---

### Cohere For AI та ініціатива Aya
Окремим стратегічним напрямом є Cohere For AI — дослідницька програма, створена для розвитку відкритих мовних моделей і підтримки глобальної наукової спільноти.
Ініціатива Aya має такі характеристики:
* фокус на багатомовні моделі, включно з мовами з обмеженими ресурсами;
* відкриті ваги моделей для дослідницького використання;
* публічні технічні звіти та бенчмарки;
* незалежність від комерційної лінійки продуктів.=
Моделі Aya 23 та Aya 101 стали прикладом того, як Cohere поєднує відкриту науку з промисловим підходом до якості та стабільності.

### Філософія кадрової та наукової політики Cohere
Cohere дотримується принципів:
* пріоритету прикладної користі моделей;
* контролю якості та відповідальності у використанні ШІ;
* мінімізації публічного “культу особистостей” на користь командної роботи;
* розділення дослідницьких і комерційних напрямів без конфлікту інтересів.
Саме ця кадрова та організаційна модель дозволила Cohere зайняти стабільну позицію серед постачальників великих мовних моделей для корпоративного сегменту.

## 5. Бенчмарки та порівняння ефективності Cohere

### 1: Pre-trained Models (Базові моделі) 

---
| Бенчмарк | # Shots | Метрика      |    Command Base   |   Command R   | Command A | Aya 23 (35B) |
| :------- | :-----: | :-----------: | :----------------: | :----------------: | :-----------: | :--------------: |
| MMLU |    5    | accuracy | Не розкривається | Не розкривається | Не розкривається |       ~60+*       |
| GSM8K |    8    | accuracy | Не розкривається | Не розкривається | Не розкривається |       ~55–60*       |
| HumanEval |    0    | pass@1 | Не розкривається | Не розкривається | Не розкривається |       ~35*      |
| TyDiQA |    1    | F1 | Не розкривається | Не розкривається | Не розкривається |      Високі результати      |
| Multilingual Benchmarks |    -    | avg score | Не розкривається | Не розкривається | Не розкривається |      Сильна сторона       |
---

### 2: Instruction Tuned Models 
Command-моделі оптимізовані для RAG, корпоративних документів та інструкцій, а не для open leaderboards.

---
| Бенчмарк         | # Shots | Метрика |    Command   |   Command R   | Command R+ | Aya 23 (35B) |
| :--------------- | :-------: | :---------: | :----------------: | :----------------: | :-----------: | :--------------: |
| MMLU Pro |    0    | accuracy   | Не публікується | Не публікується | Не публікується | Високий рівень |
| GPQA |    0    | accuracy   | Не публікується | Не публікується | Не публікується | Покращено |
| LiveCodeBench |    0    | pass@1 | Не публікується | Не публікується | Не публікується | Стабільний |
| Long Context QA |    0    | EM | Не публікується | Сильна сторона | Сильна сторона | Флагман |
| Enterprise Doc QA |    0    | EM / anls | Не публікується | Високо | Дуже високо | Максимально |
---

### 3: Search, RAG та Retrieval-бенчмарки (ключова зона Cohere)
Cohere переважає більшість LLM-провайдерів саме у retrieval-задачах.

---
| Бенчмарк         | # Shots | Метрика |    Embed v3/v4   |   Rerank 3 / 3.5   |
| :--------------- | :-------: | :---------: | :----------------: | :----------------: |
| BEIR | nDCG@10 | accuracy   | Top-tier | Top-tier |
| MSMARCO | MRR@10 | accuracy   | Дуже високий | Один з найкращих |
| Enterprise Search | Precision@k | Висока | Найвища |
| RAG QA |    0    | Answer EM | Висока | Суттєве покращення |
---
